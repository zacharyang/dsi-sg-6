{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests as rq\n",
    "import regex as re\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def collect_rss_movies(genres,countries):\n",
    "\n",
    "## Query the RSS feed to get 200 latest movies from a list of countries and across different genres ##  \n",
    "    \n",
    "    results={}\n",
    "    rss_url ='https://rss.itunes.apple.com/api/v1/%s/movies/top-movies/%s/200/explicit.json'\n",
    "    \n",
    "    for country in countries:\n",
    "        country_results=[]\n",
    "        for genre in genres:\n",
    "            r = rq.get(rss_url % (country,genre)).json()\n",
    "            genre_results=r['feed']['results']\n",
    "            country_results+= genre_results\n",
    "        results[country]=country_results\n",
    "        \n",
    "        print('%d movies indexed from %s' %((len(results[country]),country.upper())))\n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399 movies indexed from US\n",
      "400 movies indexed from SG\n",
      "399 movies indexed from MY\n",
      "400 movies indexed from ID\n",
      "400 movies indexed from AU\n"
     ]
    }
   ],
   "source": [
    "# Collect 400 movies from US and SG #\n",
    "\n",
    "genres = ['action-and-adventure','documentary']\n",
    "countries=['us','sg','my','id','au']\n",
    "movies_apac_us=collect_rss_movies(genres,countries)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Gets all movie info from itunes API by ID ## \n",
    "\n",
    "def get_info_by_id(movies_dict):\n",
    "    \n",
    "    results=[]\n",
    "    \n",
    "    for country in movies_dict.keys():\n",
    "        country_movies=[]\n",
    "        country_movie_ids=[ a['id'] for a in movies_dict[country]]\n",
    "        \n",
    "        for i in country_movie_ids:\n",
    "            r=rq.get('https://itunes.apple.com/lookup?id=%s&country=%s' % (i,country)).json()\n",
    "            country_movies += r['results']\n",
    "            \n",
    "        results+= country_movies\n",
    "        \n",
    "    return results\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Run the above and dump it in json file # \n",
    "\n",
    "apac_us_results=get_info_by_id(movies_apac_us)\n",
    "\n",
    "with open('data_apac_us_itunes.json', 'w') as outfile:\n",
    "    json.dump(apac_us_results, outfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Opens local cache of data # \n",
    "with open('./data/apac_us_itunes_data.json', 'r') as file:\n",
    "    d=json.load(file)\n",
    "    file.close()\n",
    "\n",
    "apac_us_results=d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1998"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(apac_us_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_search_dat(data):\n",
    "    \n",
    "    titles=[]\n",
    "    years=[]\n",
    "    itunes_id=[]\n",
    "    dropped_dat=[]\n",
    "\n",
    "    \n",
    "    for a in data:\n",
    "        if a['wrapperType'] =='track':\n",
    "            titles.append(a['trackName'])\n",
    "            years.append(a['releaseDate'][:4])\n",
    "            itunes_id.append(a['trackId'])\n",
    "    \n",
    "    # Drop all \"bundle\" type movies, eg. sequel bundles # \n",
    "        else:\n",
    "            dropped_dat.append(a['collectionName'])\n",
    "    print( '%s collection bundles dropped from search' % ((str(len(dropped_dat)))) )\n",
    "    \n",
    "    # Parsing - removing spaces, special characters not permitted in search string # \n",
    "    \n",
    "    names_without_bracket_y=[re.sub(r' \\([^)]*\\)', '',a) for a in titles] \n",
    "    names_without_punctuation=[re.sub(r\"[^\\w\\d-'\\s]\",'',a) for a in names_without_bracket_y]\n",
    "    names_without_punctuation_double_space=[a.replace('  ',' ') for a in names_without_punctuation]\n",
    "    search_str=[a.replace(' ','+') for a in names_without_punctuation_double_space]\n",
    "\n",
    "    seen_ind=[]\n",
    "    seen=set()\n",
    "    for i, v in enumerate(search_str):\n",
    "        if v not in seen:\n",
    "            seen_ind.append(i)\n",
    "        seen.add(v)\n",
    "    \n",
    "    search_dat={\n",
    "        \n",
    "        'titles':[titles[i] for i in seen_ind],\n",
    "        \n",
    "        'years':[years[i] for i in seen_ind],\n",
    "        \n",
    "        'search_strs':[search_str[i] for i in seen_ind],\n",
    "        \n",
    "        'itunes_id':[itunes_id[i] for i in seen_ind]\n",
    "    \n",
    "    }\n",
    "    print( '%s duplicates removed from search' % (str((len(search_str)-len(search_dat['titles'])))))\n",
    "    return search_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "43 collection bundles dropped from search\n",
      "761 duplicates removed from search\n"
     ]
    }
   ],
   "source": [
    "search_dat=get_search_dat(apac_us_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tmdb_api_key='0a1cfe6a5ac9d8391730241102367452'\n",
    "\n",
    "def get_TMDB_ids(search_dat,api_key,specify_year=True):\n",
    "    url=\"https://api.themoviedb.org/3/search/movie?api_key=%s&query=%s\"\n",
    "    id_list=[]\n",
    "    exact_matches=multiple_matches=no_matches=bad_response=0\n",
    "    \n",
    "    for a in range(len(search_dat['search_strs'])):\n",
    "        \n",
    "        if specify_year==True: \n",
    "            url_full=url%(api_key,search_dat['search_strs'][a])+'&year='+str(search_dat['years'][a])\n",
    "        else:\n",
    "            url_full=url%(api_key,search_dat['search_strs'][a])\n",
    "            \n",
    "            \n",
    "        r=rq.get(url_full)\n",
    "\n",
    "        if r.status_code==200:\n",
    "            \n",
    "            m=r.json()\n",
    "            TMdb_titles=[a['title'] for a in m['results']]\n",
    "            TMdb_id=[a['id'] for a in m['results']]\n",
    "\n",
    "            # Search for exact title match # \n",
    "            if search_dat['titles'][a] in TMdb_titles:\n",
    "                id_list.append(TMdb_id[TMdb_titles.index(search_dat['titles'][a])])\n",
    "                exact_matches+=1\n",
    "            # Search for result exact hit #\n",
    "            elif m['total_results']==1:\n",
    "                id_list.append(m['results'][0]['id'])\n",
    "                exact_matches+=1\n",
    "            # Search for multiple result hit #\n",
    "            elif m['total_results']>1:\n",
    "                id_list.append(TMdb_id)\n",
    "                multiple_matches+=1\n",
    "            # Search for null result hit #\n",
    "            elif m['total_results']==0:\n",
    "                id_list.append(TMdb_id)\n",
    "                no_matches+=1\n",
    "        # Record Bad Response #\n",
    "        else:\n",
    "            id_list.append(None)\n",
    "            bad_response+=1\n",
    "\n",
    "    search_dat['TMdb_id']=id_list\n",
    "    \n",
    "    print('Exact Matches = %d, Multiple_matches=%d, No_matches=%d, Bad Response=%d' %(exact_matches,multiple_matches,no_matches,bad_response))\n",
    "    return search_dat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Matches = 866, Multiple_matches=44, No_matches=284, Bad Response=0\n"
     ]
    }
   ],
   "source": [
    "tmdb_api_key='0a1cfe6a5ac9d8391730241102367452'\n",
    "dat_with_TMdb_id=get_TMDB_ids(search_dat,tmdb_api_key)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cache the TMdb search results data in json # \n",
    "\n",
    "with open('./data/TMdb_search_results.json', 'w') as f:\n",
    "    json.dump(dat_with_TMdb_id,f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Opens local cache of data # \n",
    "with open('./data/TMdb_search_results.json', 'r') as file:\n",
    "    d=json.load(file)\n",
    "    file.close()\n",
    "\n",
    "dat_with_TMdb_id=d\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72.53 percent of queries returned exact matches for TMdb IDs\n"
     ]
    }
   ],
   "source": [
    "## Subset the data by those with multiple matches, no matches and exact matches ## \n",
    "\n",
    "mult_ind=[isinstance(a,list) and len(a)>0 for a in dat_with_TMdb_id['TMdb_id'] ]\n",
    "multiple_IDs_run1={k:[v for i,v in enumerate(dat_with_TMdb_id[k]) if mult_ind[i]==True] for k in dat_with_TMdb_id.keys()}\n",
    "\n",
    "no_Ind=[isinstance(a,list) and len(a)==0 for a in dat_with_TMdb_id['TMdb_id'] ]\n",
    "no_matched_ids_run1={k:[v for i,v in enumerate(dat_with_TMdb_id[k]) if no_Ind[i]==True] for k in dat_with_TMdb_id.keys()}\n",
    "\n",
    "exact_ind=[isinstance(a,int)for a in dat_with_TMdb_id['TMdb_id'] ]\n",
    "exact_matches_run1={k:[v for i,v in enumerate(dat_with_TMdb_id[k]) if exact_ind[i]==True] for k in dat_with_TMdb_id.keys()}\n",
    "\n",
    "print('%.2f percent of queries returned exact matches for TMdb IDs' %float(len(exact_matches_run1['TMdb_id'])*100/len(dat_with_TMdb_id['TMdb_id'])))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Matches = 147, Multiple_matches=14, No_matches=123, Bad Response=0\n"
     ]
    }
   ],
   "source": [
    "# Run 2, relax the \"Year\" condition and search the TMdb database again ##\n",
    "\n",
    "no_matches_results=get_TMDB_ids(no_matched_ids_run1,api_key=tmdb_api_key,specify_year=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.84 percent of queries returned exact matches for TMdb IDs\n"
     ]
    }
   ],
   "source": [
    "# Subset the data again # \n",
    "\n",
    "mult_ind=[isinstance(a,list) and len(a)>0 for a in no_matches_results['TMdb_id'] ]\n",
    "multiple_IDs_run2={k:[v for i,v in enumerate(no_matches_results[k]) if mult_ind[i]==True] for k in no_matches_results.keys()}\n",
    "\n",
    "no_Ind=[isinstance(a,list) and len(a)==0 for a in no_matches_results['TMdb_id'] ]\n",
    "no_matched_ids_run2={k:[v for i,v in enumerate(no_matches_results[k]) if no_Ind[i]==True] for k in no_matches_results.keys()}\n",
    "\n",
    "exact_ind=[isinstance(a,int)for a in no_matches_results['TMdb_id'] ]\n",
    "exact_matches_run2={k:[v for i,v in enumerate(no_matches_results[k]) if exact_ind[i]==True] for k in no_matches_results.keys()}\n",
    "\n",
    "num_exact_matches_run2=len(exact_matches_run2['TMdb_id'])+len(exact_matches_run1['TMdb_id'])\n",
    "percent_exact_match= float(num_exact_matches_run2*100/len(dat_with_TMdb_id['TMdb_id']))\n",
    "\n",
    "print('%.2f percent of queries returned exact matches for TMdb IDs' % percent_exact_match )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Need to Google for 58 movies that return multiple TMdb hits and 123 movies that returned no TMdb hits\n"
     ]
    }
   ],
   "source": [
    "# Function to combine the data that is to be passed through search #\n",
    "\n",
    "def combine_search_results(results):\n",
    "    result={}\n",
    "    keys=list(results[0].keys()) # Set the keys first #\n",
    "    for k in keys:\n",
    "        result[k]=[]\n",
    "    for d in results:\n",
    "        for k,v in d.items():\n",
    "            result[k]+= v  # Add the list of data by key #\n",
    "    return result\n",
    "\n",
    "# Set up search database for multiple mathces\n",
    "\n",
    "multi_matched_search_results =[multiple_IDs_run1,multiple_IDs_run2]\n",
    "\n",
    "matched_google= combine_search_results(multi_matched_search_results)\n",
    "\n",
    "print ('Need to Google for %d movies that return multiple TMdb hits and %d movies that returned no TMdb hits' %((len(matched_google['TMdb_id']),len(no_matched_ids_run2['TMdb_id']))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def google_for_imdb_id(search_dat):\n",
    "    IMDB_ids_list=[]\n",
    "    successful_hits=0\n",
    "    no_hits=0\n",
    "    for a in range(len(search_dat['years'])):\n",
    "        \n",
    "        # Google 'Movie Name' + 'imdb' using BS#\n",
    "        r=rq.get('https://www.google.com/search?q=%s+%s+imdb'% (search_dat['search_strs'][a],search_dat['years'][a] )) \n",
    "        p= BeautifulSoup(r.text,'html.parser')\n",
    "        \n",
    "        # Take the first search result hyper link # \n",
    "        \n",
    "        first_google_hit=p.find_all('h3', {'class':'r'})[0] \n",
    "        m=re.search('title/(.+?)/&',str(first_google_hit))\n",
    "        \n",
    "        # If successful, store IMdb ids to a list, if not, store a NaN value #\n",
    "        if m:\n",
    "            IMDB_id=m.group(1)\n",
    "            IMDB_ids_list.append(IMDB_id)\n",
    "            successful_hits+=1\n",
    "        else:\n",
    "            IMDB_ids_list.append('NaN')\n",
    "            no_hits+=1\n",
    "    \n",
    "    print('Successful IMDB_ids_indexed = ' + str(successful_hits) + ' No results = '+ str(no_hits))\n",
    "    \n",
    "    # Store in the original dictionary with key 'IMdb_id' # \n",
    "    search_dat['IMdb_id']=IMDB_ids_list\n",
    "    \n",
    "    return search_dat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful IMDB_ids_indexed = 89 No results = 34\n"
     ]
    }
   ],
   "source": [
    "# Googling for results that are not matched #\n",
    "\n",
    "google_results_nomatch=google_for_imdb_id(no_matched_ids_run2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successful IMDB_ids_indexed = 57 No results = 1\n"
     ]
    }
   ],
   "source": [
    "# Googling for results that have multiple matches # \n",
    "\n",
    "google_results_multi_match=google_for_imdb_id(matched_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Function for getting IMdb ID from TMdb API # \n",
    "\n",
    "def get_imdb_id_from_tmdb_id(search_dat,api_key):\n",
    "    results=[]\n",
    "    missed=[]\n",
    "    bad_response=0\n",
    "    \n",
    "    for a in search_dat['TMdb_id']:\n",
    "        r = rq.get('https://api.themoviedb.org/3/movie/%s?api_key=%s' % (str(a),api_key))\n",
    "        \n",
    "        if r.status_code== 200:\n",
    "            m = r.json()\n",
    "            results.append(m)\n",
    "        else:\n",
    "            print('Bad Response')\n",
    "            bad_response+=1\n",
    "            \n",
    "    print('Number of Bad Responses = ' + str(bad_response))\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Bad Responses = 0\n"
     ]
    }
   ],
   "source": [
    "# Getting IMdb ID from TMdb api for exact matches # \n",
    "\n",
    "exact_matches_results=combine_search_results([exact_matches_run1,exact_matches_run2])\n",
    "\n",
    "exact_results=get_imdb_id_from_tmdb_id(exact_matches_results,tmdb_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cache the data in local directory as json #\n",
    "\n",
    "with open('data_tmdb_exact_matches.json', 'w') as outfile:\n",
    "    json.dump(exact_results, outfile)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Opens local cache of data # \n",
    "with open('data_tmdb_exact_matches.json', 'r') as file:\n",
    "    d=json.load(file)\n",
    "    file.close()\n",
    "\n",
    "exact_results=d\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "26 missing IMdb IDs from querying TMdb database\n"
     ]
    }
   ],
   "source": [
    "# Store the resulting IMdb results as from the TMdb database # \n",
    "\n",
    "imdb_ids=[a['imdb_id'] for a in exact_results]\n",
    "\n",
    "exact_matches_results['IMdb_id']=imdb_ids\n",
    "\n",
    "# Check for unsuccesful queries for IMdb_id # \n",
    "\n",
    "missed_ind=[a=='' for a in exact_matches_results['IMdb_id']]\n",
    "\n",
    "print('%d missing IMdb IDs from querying TMdb database' %sum(missed_ind) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Subset the results again #\n",
    "\n",
    "missed_tmdb_ids={k:[v for i,v in enumerate(exact_matches_results[k]) if missed_ind[i]==True] for k in exact_matches_results.keys()}\n",
    "leftover_ind= [not i for i in missed_ind]\n",
    "leftover_exact_matches={k:[v for i,v in enumerate(exact_matches_results[k]) if leftover_ind[i]==True] for k in exact_matches_results.keys()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Google for the missing IDs #\n",
    "\n",
    "google_missed_tmdb_results=google_for_imdb_id(missed_tmdb_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Merge all the data back to pass through the OMdb API # \n",
    "\n",
    "to_merge=[google_missed_tmdb_results,leftover_exact_matches,google_results_multi_match,google_results_nomatch]\n",
    "\n",
    "OMdb_search_dat=combine_search_results(to_merge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def get_data_from_omdb(search_dat,api_key,api_key2):\n",
    "# Searching through the OMdb data base, querying by IMdb ID to get the data from the OMdb database \n",
    "# Takes the search data and 2 API keys as arugments\n",
    "# 2nd API Key is in case the rate limit is reached \n",
    "\n",
    "    results=[]\n",
    "    bad_response=0\n",
    "    for imdb_id in search_dat['IMdb_id']:\n",
    "        if imdb_id == None or imdb_id== 'NaN':\n",
    "            results.append([])\n",
    "        else:\n",
    "            r=rq.get('http://www.omdbapi.com/?apikey=%s&i=%s'% (api_key, imdb_id))\n",
    "            if r.status_code== 200:\n",
    "                m = r.json()\n",
    "                results.append(m)\n",
    "            else:\n",
    "                r2=rq.get('http://www.omdbapi.com/?apikey=%s&i=%s'%(api_key2, imdb_id))\n",
    "                if r2.status_code==200:\n",
    "                    m2=r2.json()\n",
    "                    results.append(m2)\n",
    "                else:\n",
    "                    print('Bad Response for ' + str(imdb_id))\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "omdb_api_key='cd67fc6d'\n",
    "omdb_api_key2='89ae04fd'\n",
    "OMdb_results=get_data_from_omdb(OMdb_search_dat,omdb_api_key,omdb_api_key2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 IMdb IDs returned no results\n"
     ]
    }
   ],
   "source": [
    "# Check for bad results from OMdb database #\n",
    "\n",
    "missed_ind=[i for i,a in enumerate(OMdb_results) if len(a)==2]\n",
    "\n",
    "print('%d IMdb IDs returned no results' %len(missed_ind))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Cache the results # \n",
    "\n",
    "with open('./data/OMdb_data.json', 'w') as outfile:\n",
    "    json.dump(OMdb_results,outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
